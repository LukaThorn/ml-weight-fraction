{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#About\" data-toc-modified-id=\"About-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>About</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Classes\" data-toc-modified-id=\"Classes-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Classes</a></span></li><li><span><a href=\"#Style-functions\" data-toc-modified-id=\"Style-functions-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Style functions</a></span></li><li><span><a href=\"#Pre-processing-functions\" data-toc-modified-id=\"Pre-processing-functions-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Pre-processing functions</a></span></li><li><span><a href=\"#Model-functions\" data-toc-modified-id=\"Model-functions-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Model functions</a></span></li><li><span><a href=\"#Export\" data-toc-modified-id=\"Export-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Export</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the source file for classes and functions used throughout the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:04.497403Z",
     "start_time": "2019-09-30T06:57:03.593524Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:05.209943Z",
     "start_time": "2019-09-30T06:57:05.201284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure directory exists.\n"
     ]
    }
   ],
   "source": [
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "PROJECT_SAVE_DIR = \"figs\"\n",
    "\n",
    "if not (os.path.isdir(PROJECT_ROOT_DIR+'/'+PROJECT_SAVE_DIR)):\n",
    "    print('Figure directory did not exist, creating now.')\n",
    "    os.mkdir(PROJECT_ROOT_DIR+'/'+PROJECT_SAVE_DIR)\n",
    "else:\n",
    "    print('Figure directory exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:08.521733Z",
     "start_time": "2019-09-30T06:57:08.416735Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in target (ENM) model feature data\n",
    "X_enm = pd.read_csv(\"./data/ENM-preprocessed-feats.csv\", \n",
    "                    sep='\\t', header='infer', index_col=0)\n",
    "\n",
    "# Read in source (organics) model feature data\n",
    "X_source = pd.read_csv(\"./data/organics-preprocessed-feats.csv\", \n",
    "                       sep='\\t', header='infer', index_col=0)\n",
    "\n",
    "# Read in ENM labels (maximum_weight_fraction)\n",
    "y_enm = pd.read_csv(\"./data/ENM-clean.csv\", \n",
    "                    sep=',', header='infer', usecols=[4])\n",
    "\n",
    "# Read in organics labels (maximum_weight_fraction)\n",
    "y_source = pd.read_csv(\"./data/organics-preprocessed-WF.csv\", \n",
    "                       sep='\\t', header='infer', index_col=0)\n",
    "y_source.index = X_source.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:09.653555Z",
     "start_time": "2019-09-30T06:57:09.649222Z"
    }
   },
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "    \"\"\"\n",
    "    Option to suppress print output.\n",
    "    Source:\n",
    "    https://stackoverflow.com/questions/8391411/suppress-calls-to-print-python\n",
    "    \"\"\"\n",
    "    import os, sys\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:10.343192Z",
     "start_time": "2019-09-30T06:57:10.334978Z"
    }
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "class CompletionNotifier:\n",
    "    \"\"\"\n",
    "    A nestable function-completion notification decorator; (No notification\n",
    "    sound on inner functions).\n",
    "    Source:\n",
    "    https://gist.github.com/jdpage/26376472ac18a7057e381f2259c7b988\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, notify_fun):\n",
    "        self.notify_fun = notify_fun\n",
    "        self.isinner = False\n",
    "\n",
    "    def __call__(self, f):\n",
    "        # return f # to disable\n",
    "        @functools.wraps(f)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            isinner = self.isinner\n",
    "            self.isinner = True\n",
    "            try:\n",
    "                return f(*args, **kwargs)\n",
    "            finally:\n",
    "                self.isinner = isinner\n",
    "                if not self.isinner:\n",
    "                    self.notify_fun(f)\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "# To enable notification sound to play\n",
    "def ping_notify(*args):\n",
    "    from IPython.display import Audio\n",
    "    sound_file = './data/ping.wav'\n",
    "    display(Audio(url=sound_file, autoplay=True))\n",
    "    \n",
    "notify_on_complete = CompletionNotifier(ping_notify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:11.779884Z",
     "start_time": "2019-09-30T06:57:10.872655Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class EstimatorSelectionHelper:\n",
    "    \"\"\"\n",
    "    Set up grid search across multiple estimators, pipelines; automatically \n",
    "    performs stratified CV if labels are multiclass.\n",
    "    By David Bastista:\n",
    "    http://www.davidsbatista.net/blog/2018/02/23/model_optimization/\n",
    "    \"\"\"\n",
    "    \n",
    "    cv=10\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" \n",
    "                             % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=cv, n_jobs=1, verbose=1, \n",
    "            scoring='accuracy', refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:12.085428Z",
     "start_time": "2019-09-30T06:57:12.079023Z"
    }
   },
   "outputs": [],
   "source": [
    "def highlight_max(data, color='red'):\n",
    "    \"\"\"\n",
    "    Highlight the maximum in a Series or DataFrame.\n",
    "    Source:\n",
    "    https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html\n",
    "    \"\"\"\n",
    "    attr = 'background-color: {}'.format(color)\n",
    "    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "        is_max = data == data.max()\n",
    "        return [attr if v else '' for v in is_max]\n",
    "    else:  # from .apply(axis=None)\n",
    "        is_max = data == data.max().max()\n",
    "        return pd.DataFrame(np.where(is_max, attr, ''),\n",
    "                            index=data.index, columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:12.523996Z",
     "start_time": "2019-09-30T06:57:12.520430Z"
    }
   },
   "outputs": [],
   "source": [
    "def recolor_text(scalar, color='white'):\n",
    "    \"\"\"\n",
    "    Recolor text of a scaler that is equal to 'value' criterion. \n",
    "    Suggested use with df.style.applymap(recolor_text).\n",
    "    \n",
    "    Adapted from:\n",
    "    https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html\n",
    "    \"\"\"\n",
    "    color = color if scalar == 0 else 'black'\n",
    "    return 'color: %s' % color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:12.935850Z",
     "start_time": "2019-09-30T06:57:12.927998Z"
    }
   },
   "outputs": [],
   "source": [
    "def rgba2hex(rgba):\n",
    "    \n",
    "    \"\"\"Convert RGBA tuples representing a color to hexadecimal code\"\"\"\n",
    "    \n",
    "    r, g, b, a = (int(c*255) for c in rgba)\n",
    "    return f\"#{r:02x}{g:02x}{b:02x}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:13.713189Z",
     "start_time": "2019-09-30T06:57:13.706382Z"
    }
   },
   "outputs": [],
   "source": [
    "def bins(row):\n",
    "    \"\"\"\n",
    "    Assign weight fractions (continuous) to bins (int).\n",
    "    Class ranges are different from those used by Isaacs et al. 2016.\n",
    "    \"\"\"\n",
    "    if row['maximum_weight_fraction'] <= 0.0001:\n",
    "        val = 0 # low\n",
    "    elif row['maximum_weight_fraction'] > 0.01:\n",
    "        val = 2 # high\n",
    "    else:\n",
    "        val = 1 # medium\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:14.450564Z",
     "start_time": "2019-09-30T06:57:14.169447Z"
    }
   },
   "outputs": [],
   "source": [
    "bin_enm = np.asarray(y_enm.apply(bins, axis=1))\n",
    "bin_source = np.asarray(y_source.apply(bins, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:14.904644Z",
     "start_time": "2019-09-30T06:57:14.893656Z"
    }
   },
   "outputs": [],
   "source": [
    "def bar_graph_bins(label_data,\n",
    "                   data_composition):\n",
    "    \"\"\"\n",
    "    This function creates a bar graph of weight fraction bins and prints the \n",
    "    count and frequency for each.\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    label_data: int array of shape [n,]\n",
    "        Dataframe containing binned wf data\n",
    "    data_composition: string\n",
    "        Describes the chemical composition of label_data \n",
    "        for use in the plot title; e.g., `ENM`, `Organics`   \n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Find the count, frequency of WF bins\n",
    "    unique, counts = np.unique(label_data, return_counts=True)\n",
    "    wf_distrib = dict(zip(unique, counts))\n",
    "    freq = []\n",
    "    for i in counts:\n",
    "        percent = (i/np.sum(counts)).round(2)\n",
    "        freq.append(percent)\n",
    "\n",
    "    # Plot\n",
    "    plt.bar(range(len(wf_distrib)), list(wf_distrib.values()), align='center')\n",
    "    plt.xticks(range(len(wf_distrib)), list(['low','medium','high']))\n",
    "    plt.title('Frequency of %s Weight Fraction Bins' % data_composition)\n",
    "    plt.show()\n",
    "    \n",
    "    print('Label bin: ', unique)\n",
    "    print('Count    : ', counts)\n",
    "    print('Frequency: ', freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:15.554524Z",
     "start_time": "2019-09-30T06:57:15.542153Z"
    }
   },
   "outputs": [],
   "source": [
    "def feat_agglom(n_clust, prefix, df_fit, df_trans=None):\n",
    "    \"\"\"\n",
    "    Apply feature agglomeration to get a list of new column names. \n",
    "    If `df_trans` is provided, returns the reduced feature data frame.\n",
    "    `prefix` is the four character indicator that the column was agglomerated.\n",
    "    \"\"\"\n",
    "    from sklearn.cluster import FeatureAgglomeration\n",
    "    \n",
    "    # ===== Fit feature agglomeration =====\n",
    "    agg = FeatureAgglomeration(n_clust, affinity=\"cosine\", linkage=\"average\")\n",
    "    agg.fit(df_fit + 0.0001)\n",
    "    \n",
    "    # ===== Get agglomerated feature labels =====\n",
    "    # Create array showing order for agglomerated features\n",
    "    ord_arr = np.column_stack((agg.labels_, df_fit.columns))\n",
    "    # Agglomerate names of agglomerated features    \n",
    "    len_orig = len(df_fit.columns)\n",
    "    kids = agg.children_\n",
    "    for i in np.arange(0, len_orig - n_clust):\n",
    "        str1, str2 = df_fit.columns[kids[i,0]], df_fit.columns[kids[i,1]]\n",
    "        name = '_'.join([prefix, str1[5:], str2[5:]])\n",
    "        ord_arr[ord_arr==str1] = name\n",
    "        ord_arr[ord_arr==str2] = name\n",
    "    # Sort order\n",
    "    ord_arr = ord_arr[ord_arr[:,0].argsort()]\n",
    "    # Remove duplicates\n",
    "    agg_cols = list(pd.unique(ord_arr[:,1]))\n",
    "    \n",
    "    # ===== Apply agglomeration =====\n",
    "    if df_trans is not None:\n",
    "        df_red = pd.DataFrame(agg.transform(df_trans), columns=agg_cols)\n",
    "        # Alphabetize features\n",
    "        agg_cols.sort()\n",
    "        df_red = df_red[agg_cols]\n",
    "        return df_red\n",
    "    else:\n",
    "        return agg_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:17.420587Z",
     "start_time": "2019-09-30T06:57:17.407046Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_param_opt(param_grid, test_scores, scoring): \n",
    "    \n",
    "    \"\"\"\n",
    "    Optional plot of validation score vs classifier parameter(s). For use \n",
    "    after running parameter optimization with GridSearchCV.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    def convert_log_scale(n_set, n_label):\n",
    "        log_dif = np.abs(np.log10(max(n_set)) - np.log10(min(n_set)))\n",
    "        if log_dif > 3:\n",
    "            n_set = np.log10(n_set)\n",
    "            n_label = ('log_10(%s)' % n_label)    \n",
    "        return n_set, n_label\n",
    "\n",
    "    params = {k.split(\"__\")[1]: v for k, v in param_grid.items()}\n",
    "    param1 = list(params.keys())[0]\n",
    "    param1_set = list(params.values())[0]\n",
    "    param1_set, param1 = convert_log_scale(param1_set, param1)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    if len(param_grid.keys()) == 1:\n",
    "        plt.plot(param1_set, test_scores, 'k.-', ms=8, lw=2)\n",
    "        plt.title('%s vs %s' % (scoring.title(), param1))\n",
    "        plt.xlabel(param1)\n",
    "        plt.ylabel(scoring.title())\n",
    "        plt.xticks(np.arange(min(param1_set), max(param1_set) + 2, 2))\n",
    "    elif len(param_grid.keys()) == 2:\n",
    "        param2 = list(params.keys())[1]\n",
    "        param2_set = list(param_grid.values())[1]\n",
    "        param2_set, param2 = convert_log_scale(param2_set, param2)\n",
    "        test_scores = np.reshape(test_scores, newshape=[-1, len(param2_set)])\n",
    "        plt.contourf(param2_set, param1_set, test_scores)\n",
    "        plt.title('%s Contours Over Parameter Grid' % scoring.title())\n",
    "        plt.xlabel(param2)\n",
    "        plt.ylabel(param1)\n",
    "        plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T09:39:18.820469Z",
     "start_time": "2019-09-30T09:39:18.790661Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_feat_impt(feat_names, \n",
    "                   importances, \n",
    "                   variances=None, \n",
    "                   save_fig_name=None,\n",
    "                   combo_impt=False):\n",
    "    \"\"\"\n",
    "    This function uses results from an rfc as input to plot feature importance.\n",
    "    Here, the rfc determines importance using what is known as gini importance \n",
    "    or mean decrease impurity. Includes option to combine features into more \n",
    "    easily interpretable groups.\n",
    "    \n",
    "    References:\n",
    "    https://stackoverflow.com/questions/15810339/how-are-feature-importances-in-randomforestclassifier-determined\n",
    "    https://matplotlib.org/examples/api/barchart_demo.html\n",
    "    https://stackoverflow.com/questions/28931224/adding-value-labels-on-a-matplotlib-bar-chart\n",
    "    https://stackoverflow.com/questions/14849293/python-find-index-position-in-list-based-of-partial-string\n",
    "    \"\"\" \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # (Optional) Sum importance by feature group\n",
    "    if combo_impt:\n",
    "        idx_cprp = [i for i, s in enumerate(feat_names) if 'cprp' in s]\n",
    "        idx_mtrx = [i for i, s in enumerate(feat_names) if 'mtrx' in s]\n",
    "        idx_func = [i for i, s in enumerate(feat_names) if 'fagg' or 'func' in s]\n",
    "        idx_prod = [i for i, s in enumerate(feat_names) if 'pagg' or 'pgen' or \\\n",
    "                    'pgrp' in s]\n",
    "        importances = np.asarray([np.sum(importances[idx_cprp]), \n",
    "                                  np.sum(importances[idx_func]), \n",
    "                                  np.sum(importances[idx_prod]), \n",
    "                                  np.sum(importances[idx_mtrx])])\n",
    "        # (Optional) Sum variance by feature group\n",
    "        if np.all(variances != None):\n",
    "            variances = np.asarray([np.sum(variances[idx_cprp]), \n",
    "                                    np.sum(variances[idx_func]),\n",
    "                                    np.sum(variances[idx_prod]),\n",
    "                                    np.sum(variances[idx_mtrx])])\n",
    "        feat_names = ['chemProperties', 'functionalUses', \n",
    "                      'productCategories', 'productMatrix']\n",
    "    \n",
    "    indices = np.argsort(importances)\n",
    "    \n",
    "    # (Optional) Add error bars\n",
    "    if np.all(variances != None):\n",
    "        err_bars = np.sqrt(variances)\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.grid(True)\n",
    "        ax.barh(range(len(indices)), importances[indices], \n",
    "                 xerr=err_bars[indices], capsize=3, align='center')\n",
    "    else: \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.barh(range(len(indices)), importances[indices], align='center')\n",
    "    \n",
    "    # Add grid lines\n",
    "    plt.grid(False)\n",
    "    ax.set_xticks(np.arange(0, np.amax(importances)+0.1, 0.05))\n",
    "    ax.xaxis.grid(color='silver')\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    # Label parts of plot\n",
    "    ax.set_title('Feature Importance')\n",
    "    ax.set_xlabel('Relative Importance')\n",
    "    ax.set_yticks(np.arange(len(feat_names)))\n",
    "    ax.set_yticklabels([feat_names[i] for i in indices])\n",
    "    # Add importance value labels at the end of bars\n",
    "    if variances is None:\n",
    "        for rect in ax.patches:\n",
    "            # Get X and Y placement of label from rect\n",
    "            x_value = rect.get_width()\n",
    "            y_value = rect.get_y() + rect.get_height() / 2\n",
    "            # Use X value as label and format number with one decimal place\n",
    "            label = \"{:.2f}\".format(x_value)\n",
    "            # Create annotation\n",
    "            plt.annotate(\n",
    "                label,\n",
    "                (x_value, y_value),         # Place label at end of the bar\n",
    "                xytext=(4, 0),              # Horizontally shift label\n",
    "                textcoords=\"offset points\", # Interpret `xytext` as offset\n",
    "                va='center', ha='left')\n",
    "    \n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    if combo_impt: fig.set_size_inches(10, 6)\n",
    "    else: fig.set_size_inches(10, 10)\n",
    "    if np.all(save_fig_name != None):\n",
    "        fig.savefig('./figs/feature_importance_%s.png' % save_fig_name, \n",
    "                   bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:19.081787Z",
     "start_time": "2019-09-30T06:57:19.070581Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_conf_matrix(cm, \n",
    "                     classes, \n",
    "                     normalize=True, \n",
    "                     cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \n",
    "    Adapted from:\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import itertools\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        title = 'Normalized Confusion Matrix'\n",
    "        print(title)\n",
    "    else:\n",
    "        title='Confusion Matrix'\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    np.set_printoptions(precision=2)\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "    plt.gcf().subplots_adjust(bottom=0.2)\n",
    "    plt.ylabel('True weight fraction')\n",
    "    plt.xlabel('Predicted weight fraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References for implementing the augment function: \n",
    "* https://stackoverflow.com/questions/34226400/find-the-index-of-the-k-smallest-values-of-a-numpy-array\n",
    "* https://stackoverflow.com/questions/22117834/how-do-i-return-a-list-of-the-3-lowest-values-in-another-list\n",
    "* http://dataaspirant.com/2015/04/11/five-most-popular-similarity-measures-implementation-in-python/\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_distances.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:21.845589Z",
     "start_time": "2019-09-30T06:57:21.832088Z"
    }
   },
   "outputs": [],
   "source": [
    "def augment(aug_type, \n",
    "            k, \n",
    "            X_enm_train, \n",
    "            bin_enm_train, \n",
    "            random_state, \n",
    "            X_source=X_source):\n",
    "    \n",
    "    \"\"\"\n",
    "    Augment ENM data with source (organics) data using either random \n",
    "    augmentation, unsupervised matching augmentation, or supervised matching \n",
    "    augmentation. Returns augmented data as numpy arrays.\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    aug_type: string ('none','random','uns_match', or 'sup_match')\n",
    "        The type of data augmentation to implement. \n",
    "        * none: no augmentation is performed; k must be zero.\n",
    "        * random: randomly samples source data to pair with ENM data.\n",
    "        * uns_match: match \"k\" most similar organics samples to ENM samples \n",
    "            based on smallest cosine distance between ENM and organics samples\n",
    "            (i.e., in an supervised fashion).\n",
    "        * sup_match: match \"k\" most similar organics samples to ENM samples \n",
    "            based on the smallest average of cosine distance between samples \n",
    "            and distance between WF labels (i.e., in an supervised fashion)\n",
    "    k: int ([0,200])\n",
    "        The number of organics samples to match with each ENM sample.\n",
    "    X_enm_train: DataFrame\n",
    "        ENM feature data to be augmented; typically a training subset for CV.\n",
    "    bin_enm_train: ndarray\n",
    "        ENM WF bin data to be augmented; typically a training subset for CV. \n",
    "    random_state: int\n",
    "        Which random seed to use.\n",
    "    \"\"\"\n",
    "    import random as pyrandom    \n",
    "    from numpy import random\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.metrics.pairwise import cosine_distances\n",
    "    \n",
    "    pyrandom.seed(random_state)\n",
    "    \n",
    "    # ===No augmentation===\n",
    "    if (aug_type=='none' or k==0):\n",
    "        X_aug, bin_aug = X_enm_train, bin_enm_train\n",
    "    \n",
    "    else:\n",
    "        # ===Random augmentation===\n",
    "        if aug_type=='random': \n",
    "            n_samples = k * len(X_enm_train) # number of samples to select\n",
    "            # Obtain indices of randomly sampled source (organics) data\n",
    "            idx_match_name = pyrandom.sample(list(X_source.index), n_samples)\n",
    "            idx_match = [X_source.index.get_loc(i) for i in idx_match_name]\n",
    "            \n",
    "        # ===Matching augmentation===\n",
    "        else:\n",
    "            # Scale/normalize data\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            scaler.fit(np.concatenate((X_enm_train, X_source)))\n",
    "            X_enm_scaled = scaler.transform(X_enm_train)\n",
    "            X_source_scaled = scaler.transform(X_source)\n",
    "            \n",
    "            # Cosine distance matrix\n",
    "            cosdist_samples = cosine_distances(X_source_scaled, X_enm_scaled)\n",
    "\n",
    "            # For supervised matching augmentation, also consider WF labels\n",
    "            if aug_type=='sup_match':\n",
    "                # Turn 1D label arrays into 2D arrays\n",
    "                bin_enm_2d = np.tile(bin_enm_train, (len(bin_source), 1))\n",
    "                bin_source_2d = np.tile(bin_source, \n",
    "                                        (len(bin_enm_train), 1)).transpose()\n",
    "                # Get normalized distance between ENM and organics labels\n",
    "                dist_bins = scaler.fit_transform(\n",
    "                    np.abs(bin_enm_2d - bin_source_2d).astype(float))\n",
    "                # Average distances of features and labels\n",
    "                dist_matrix = (cosdist_samples + dist_bins) / 2\n",
    "            else:\n",
    "                # For unsupervised matching, use plain cosine distance matrix\n",
    "                dist_matrix = cosdist_samples\n",
    "\n",
    "            # For either unsupervised or supervised matching:\n",
    "            # Loop over distance matrix in search of k-smallest distances\n",
    "            idx_match = []\n",
    "            for col in dist_matrix.T:\n",
    "                # Find organics data indices of k-smallest distances\n",
    "                matches = np.argpartition(col, k)[:k]\n",
    "                idx_match.extend(matches)\n",
    "\n",
    "        # ===All augmentation===\n",
    "        # Create X and y data frames of matches using the matching index list\n",
    "        X_match = X_source.iloc[idx_match,:]\n",
    "        bin_match = bin_source[idx_match]\n",
    "\n",
    "        # Append sampled organics data to ENM data\n",
    "        X_aug = np.concatenate((X_enm_train, X_match))\n",
    "        bin_aug = np.concatenate((bin_enm_train, bin_match))\n",
    "\n",
    "    return X_aug, bin_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:25.936349Z",
     "start_time": "2019-09-30T06:57:25.903388Z"
    }
   },
   "outputs": [],
   "source": [
    "@notify_on_complete # play sound at completion\n",
    "def model_opt_exe(classifier, \n",
    "                  aug_type, \n",
    "                  k, \n",
    "                  feat_data=X_enm, \n",
    "                  bin_data=bin_enm, \n",
    "                  seed=random.randint(1,100), \n",
    "                  save_fig_name=None, \n",
    "                  show_opt_plot=False, \n",
    "                  show_feat_impt=False, \n",
    "                  show_cnf_matrix=False, \n",
    "                  use_balanced_accu=True, \n",
    "                  param_grid=None):\n",
    "    \"\"\"\n",
    "    This function consists of two parts:  \n",
    "    1) Optimize parameters for a classifier, either SVC-RBF or RFC, with the \n",
    "    option to augment training data. \n",
    "    2) Fit model pipeline to training data using optimized parameters and \n",
    "    stratified leave-one-out k-fold cross validation;\n",
    "    3) Execute optimized model and summarize its accuracy in a confusion \n",
    "    matrix broken down by WF bins. Formatted confusion matrices are saved as \n",
    "    .png files.\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    classifier: string ('svc' or 'rfc')\n",
    "        The classifier to use in the pipeline; 'svc' refers to an SVC-RBF\n",
    "    aug_type: string ('none','random','uns_match', or 'sup_match')\n",
    "        The type of data augmentation to implement. \n",
    "        * none: no data augmentation is performed; k must be zero.\n",
    "        * random: randomly samples source data to pair with ENM data.\n",
    "        * uns_match: match \"k\" most similar organics samples to ENM samples \n",
    "            based on smallest cosine distance between ENM and organics samples\n",
    "            (i.e., in an supervised fashion).\n",
    "        * sup_match: match \"k\" most similar organics samples to ENM samples \n",
    "            based on the smallest average of cosine distance between samples \n",
    "            and distance between WF labels (i.e., in an supervised fashion)\n",
    "    k: int ([0,200])\n",
    "        The number of organics samples to match with each ENM sample.\n",
    "    feat_data: DataFrame (default=X_enm)\n",
    "        Feature data\n",
    "    bin_data: ndarray (default=bin_enm)\n",
    "        WF bin data\n",
    "    seed: int (default=random.randint(1,100))\n",
    "        Option to set the seed for CV\n",
    "    save_fig_name: string (default=None)\n",
    "        A unique string used at the end of confusion matrix and feature \n",
    "        importance (rfc-only) file names for exporting the figures as .png; \n",
    "        `None` indicates that no figures should be saved\n",
    "    show_opt_plot: bool (default=False)\n",
    "        `True` will plot accuracy as contour lines on the parameter grid\n",
    "    show_feat_impt: bool (default=False)\n",
    "        Only applicable when classifier is 'rfc'; `True` takes results from \n",
    "        an rfc as input to plot a bar graph of feature importance.\n",
    "    show_cnf_matrix: bool (default=False)\n",
    "        `True` results in matrix graphics being printed as output\n",
    "    use_balanced_accu: bool (default='balanced')\n",
    "        Normal accuracy or balanced accuracy\n",
    "    param_grid: dict (default=None)\n",
    "        See param_grid for sklearn's GridSearchCV\n",
    "    \"\"\"     \n",
    "    from numpy import random\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn import model_selection\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.metrics.pairwise import cosine_distances\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import balanced_accuracy_score\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Set scoring options using function\n",
    "    def accuracy(y_true, y_predict):\n",
    "        if use_balanced_accu: \n",
    "            accu = balanced_accuracy_score(y_true, y_predict)\n",
    "        else: accu = accuracy_score(y_true, y_predict)\n",
    "        return accu\n",
    "    if use_balanced_accu: scoring = 'balanced accuracy'\n",
    "    else: scoring = 'accuracy'\n",
    "    \n",
    "    # =====PART 1=====\n",
    "    # Optimize parameters\n",
    "    \n",
    "    # Rename feature and label data\n",
    "    X = np.array(feat_data)\n",
    "    y = bin_data\n",
    "    # Rename parameter data\n",
    "    params = {k.split(\"__\")[1]: v for k, v in param_grid.items()}\n",
    "    param1_set, param2_set = [v for v in param_grid.values()]\n",
    "\n",
    "    # Set smallest class size as number of CV folds for leave-one-out CV\n",
    "    _, class_counts = np.unique(bin_data, return_counts=True)\n",
    "    num_folds = min(class_counts)\n",
    "    if num_folds > 30: num_folds = 16\n",
    "    else: num_folds = num_folds\n",
    "    # Additional cross validation settings\n",
    "    skfold = StratifiedKFold(n_splits=num_folds, \n",
    "                             shuffle=True, \n",
    "                             random_state=seed)\n",
    "    # Objects to hold performance results\n",
    "    train_accu = np.zeros([num_folds, len(param1_set),len(param2_set)])\n",
    "    valid_accu = np.zeros([num_folds, len(param1_set),len(param2_set)])\n",
    "    # Find best algorithm parameters by searching over a grid using the CV\n",
    "    # conditions specified above\n",
    "    q=0\n",
    "    for train_index, test_index in skfold.split(X, y):\n",
    "        # Split data\n",
    "        X_train, y_train = X[train_index], y[train_index]\n",
    "        X_valid, y_valid = X[test_index], y[test_index]\n",
    "        # Augment data (if applicable) using custom function after the data \n",
    "        # split to prevent data leakage\n",
    "        if not (aug_type == 'none' or k == 0): \n",
    "            X_train, y_train = augment(aug_type, \n",
    "                                       k, \n",
    "                                       X_train, \n",
    "                                       y_train, \n",
    "                                       random_state=seed)\n",
    "        # Parameter grid search\n",
    "        r=0\n",
    "        for param1_val in param1_set:\n",
    "            s=0\n",
    "            for param2_val in param2_set:\n",
    "                fold_params = dict([(list(params.keys())[0], param1_val), \n",
    "                                    (list(params.keys())[1], param2_val)])\n",
    "                # Define pipeline options for parameter optimization\n",
    "                if classifier == 'rfc':\n",
    "                    rfc = RandomForestClassifier(class_weight='balanced', \n",
    "                                                 random_state=seed, \n",
    "                                                 **fold_params)\n",
    "                    pipe = Pipeline([\n",
    "                        ('scale', MinMaxScaler()), # normalization from 0 to 1\n",
    "                        ('estimator', rfc)\n",
    "                    ])\n",
    "                else:\n",
    "                    svc = SVC(kernel='rbf', \n",
    "                              class_weight='balanced', # balance by class size\n",
    "                              random_state=seed, \n",
    "                              **fold_params)\n",
    "                    pipe = Pipeline([\n",
    "                        ('scale', MinMaxScaler()), # normalization from 0 to 1\n",
    "                        ('estimator', svc)\n",
    "                    ])    \n",
    "                pipe.fit(X_train, y_train)\n",
    "                train_accu[q,r,s] = accuracy(y_train, pipe.predict(X_train))\n",
    "                valid_accu[q,r,s] = accuracy(y_valid, pipe.predict(X_valid))\n",
    "                s+=1\n",
    "            r+=1\n",
    "        q+=1\n",
    "    \n",
    "    # Average accuracy for grid search settings\n",
    "    avg_valid_accu = np.around(np.mean(valid_accu, axis=0), decimals=3)\n",
    "    # Get coordinates of best accuracy to locate parameters\n",
    "    coords = np.argwhere(avg_valid_accu == np.max(avg_valid_accu))\n",
    "    best_params = dict([(list(params.keys())[0], param1_set[coords[0,0]]), \n",
    "                        (list(params.keys())[1], param2_set[coords[0,1]])])\n",
    "    # If optimization plotting is set as True, use custom function\n",
    "    # to plot a 2D or contour plot to visualize accuracy \"hot spots\"\n",
    "    if show_opt_plot:\n",
    "        plot_param_opt(param_grid, avg_valid_accu, scoring)\n",
    "    \n",
    "    # Print best accuracy and parameter values\n",
    "    print('Random state:\\t', seed)\n",
    "    print('Best parameters:', best_params)\n",
    "    print('Max opt. %s: %.3f' % (scoring, np.max(avg_valid_accu)))\n",
    "    \n",
    "    # =====PART 2=====\n",
    "    # Fit optimized model\n",
    "    \n",
    "    # Fit and run pipeline using CV conditions defined above  \n",
    "    cnf_matrix = np.zeros([3,3]) # 3 \"true\" vs 3 \"predicted\" WF bins\n",
    "    for train_index, test_index in skfold.split(X, y):\n",
    "        # Split data\n",
    "        X_train, y_train = X[train_index], y[train_index]\n",
    "        X_test, y_test = X[test_index], y[test_index]\n",
    "        # Augment data (if applicable) using custom function after the data \n",
    "        # split to prevent data leakage\n",
    "        if not (aug_type == 'none' or k == 0): \n",
    "            X_train, y_train = augment(aug_type, \n",
    "                                       k, \n",
    "                                       X_train, \n",
    "                                       y_train, \n",
    "                                       random_state=seed)\n",
    "        # Define pipeline options for parameter optimization\n",
    "        if classifier == 'rfc':\n",
    "            rfc = RandomForestClassifier(class_weight='balanced', \n",
    "                                         random_state=seed, \n",
    "                                         **best_params)\n",
    "            pipe = Pipeline([\n",
    "                ('scale', MinMaxScaler()), # normalization from 0 to 1\n",
    "                ('estimator', rfc)\n",
    "            ])\n",
    "            pipe.fit(X_train, y_train)\n",
    "            importances = rfc.feature_importances_\n",
    "            # Optional plot feature importance (rfc only)\n",
    "            if show_feat_impt:\n",
    "                feature_names = feat_data.columns.values\n",
    "                plot_feat_impt(feature_names, importances, save_fig_name)\n",
    "        else:\n",
    "            svc = SVC(kernel='rbf', \n",
    "                      class_weight='balanced', # balance by class size\n",
    "                      random_state=seed, \n",
    "                      **best_params)\n",
    "            pipe = Pipeline([\n",
    "                ('scale', MinMaxScaler()), # normalization from 0 to 1\n",
    "                ('estimator', svc)\n",
    "            ])    \n",
    "            pipe.fit(X_train, y_train)\n",
    "        # Write accuracy results to confusion matrix\n",
    "        cnf_matrix += confusion_matrix(y_test, pipe.predict(X_test))\n",
    "    \n",
    "    # Calculate the average normalized accuracy across all bins\n",
    "    cm_norm = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:,np.newaxis]\n",
    "    avg_norm = (cm_norm[0,0] + cm_norm[1,1] + cm_norm[2,2]) / 3\n",
    "    print('Avg. %s:     %.3f' % (scoring, avg_norm))\n",
    "    \n",
    "    # Plot and save normalized confusion matrix\n",
    "    fig = plt.figure()\n",
    "    plot_conf_matrix(cnf_matrix, classes=[\"low\",\"mid\",\"high\"])\n",
    "    if np.all(save_fig_name != None):\n",
    "        fig.savefig('./figs/confusion_norm_%s.png' % save_fig_name)\n",
    "    if not show_cnf_matrix: plt.close(fig)\n",
    "    \n",
    "    # Set output based on chosen classifier\n",
    "    if classifier == 'rfc': return avg_norm, importances\n",
    "    else: return avg_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T06:57:27.501983Z",
     "start_time": "2019-09-30T06:57:27.488573Z"
    }
   },
   "outputs": [],
   "source": [
    "@notify_on_complete  # play sound at completion\n",
    "def multi_trials(num_trials, \n",
    "                 model_params=None, \n",
    "                 print_results=False):\n",
    "    \"\"\"\n",
    "    This function repeats model_opt and model_eval for a specified number of \n",
    "    trials and provides summary statistics. Returns avg mean (scalar), \n",
    "    avg stdev (scalar), and optionally, for RFC, arrays for average feature \n",
    "    importance and variance.\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    num_trials: int\n",
    "        The number of times to repeat\n",
    "    model_params: dict\n",
    "        A dictionary of parameters to run model_opt_exe \n",
    "    \"\"\"  \n",
    "    seed_set = np.random.choice(np.arange(1,101), \n",
    "                                size=num_trials, \n",
    "                                replace=False)\n",
    "    with HiddenPrints():   # Hides function output for all the trials\n",
    "        rs = []\n",
    "        for seed in seed_set:\n",
    "            model_params['seed'] = seed\n",
    "            # Apply all-in-one function that optimizes and executes model\n",
    "            rs_row = model_opt_exe(**model_params)\n",
    "            rs.append(rs_row)\n",
    "    # For RFC, write accuracy and feature importance results\n",
    "    if model_params['classifier'] == 'rfc':\n",
    "        results_accu = np.array([x for x, _ in rs]) # list comprehension\n",
    "        results_impt = np.array([y for _, y in rs])\n",
    "        avg_impt = results_impt.mean(axis=0)        # average importance\n",
    "        var_impt = results_impt.var(axis=0)         # variance of importance\n",
    "    # For SVC-RBF, only write accuracy results\n",
    "    else:\n",
    "        results_accu = np.array([x for x in rs])\n",
    "       \n",
    "    mu = np.around(results_accu.mean(), decimals=3)   # average across trials\n",
    "    sigma = np.around(results_accu.std(), decimals=3) # standard deviation\n",
    "    \n",
    "    # Print summary statistics across trials\n",
    "    print(\"Avg accuracy:    \", mu)\n",
    "    print(\"Median accuracy: \", np.around(np.median(results_accu), decimals=3))\n",
    "    print(\"StdDev accuracy: \", sigma)\n",
    "    print(\"Numer of trials: \", num_trials)\n",
    "    if print_results: \n",
    "        print(\"Results: \", [round(x, 2) for x in list(results_accu)])\n",
    "    \n",
    "    # Set output based on chosen classifier\n",
    "    if model_params['classifier'] == 'rfc':\n",
    "        return mu, sigma, avg_impt, var_impt\n",
    "    else: \n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T09:41:08.261066Z",
     "start_time": "2019-09-30T09:41:05.487275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook functions.ipynb to script\n",
      "[NbConvertApp] Writing 35258 bytes to functions.py\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    !jupyter nbconvert --to script functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
