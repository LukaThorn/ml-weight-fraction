{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#About\" data-toc-modified-id=\"About-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>About</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Classes\" data-toc-modified-id=\"Classes-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Classes</a></span></li><li><span><a href=\"#Pre-processing-functions\" data-toc-modified-id=\"Pre-processing-functions-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Pre-processing functions</a></span></li><li><span><a href=\"#Model-functions\" data-toc-modified-id=\"Model-functions-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model functions</a></span></li><li><span><a href=\"#Export\" data-toc-modified-id=\"Export-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Export</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the source file for classes and functions used throughout the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:53:22.432895Z",
     "start_time": "2019-07-20T11:53:22.420184Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:53:22.943847Z",
     "start_time": "2019-07-20T11:53:22.934542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure directory exists.\n"
     ]
    }
   ],
   "source": [
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "PROJECT_SAVE_DIR = \"figs\"\n",
    "\n",
    "if not (os.path.isdir(PROJECT_ROOT_DIR+'/'+PROJECT_SAVE_DIR)):\n",
    "    print('Figure directory did not exist, creating now.')\n",
    "    os.mkdir(PROJECT_ROOT_DIR+'/'+PROJECT_SAVE_DIR)\n",
    "else:\n",
    "    print('Figure directory exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:53:23.332620Z",
     "start_time": "2019-07-20T11:53:23.323672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"./data/ping.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To enable a specified sound to play\n",
    "from IPython.display import Audio\n",
    "sound_file = './data/ping.wav'\n",
    "\n",
    "# Option to play sound at the end of a function with a long run time\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:53:23.821523Z",
     "start_time": "2019-07-20T11:53:23.691161Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in target (ENM) model feature data\n",
    "X_enm = pd.read_csv(\"./data/ENM-preprocessed-feats.csv\", \n",
    "                    sep='\\t', header='infer', index_col=0)\n",
    "\n",
    "# Read in source (organics) model feature data\n",
    "X_source = pd.read_csv(\"./data/organics-preprocessed-feats.csv\", \n",
    "                       sep='\\t', header='infer', index_col=0)\n",
    "\n",
    "# Read in ENM labels (maximum_weight_fraction)\n",
    "y_enm = pd.read_csv(\"./data/ENM-clean.csv\", \n",
    "                    sep=',', header='infer', usecols=[3])\n",
    "\n",
    "# Read in organics labels (maximum_weight_fraction)\n",
    "y_source = pd.read_csv(\"./data/organics-preprocessed-WF.csv\", \n",
    "                       sep=',', header='infer')\n",
    "y_source.index = X_source.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:53:27.383990Z",
     "start_time": "2019-07-20T11:53:27.375774Z"
    }
   },
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "    \"\"\"\n",
    "    Option to suppress print output.\n",
    "    Source:\n",
    "    https://stackoverflow.com/questions/8391411/suppress-calls-to-print-python\n",
    "    \"\"\"\n",
    "    import os, sys\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:53:27.731828Z",
     "start_time": "2019-07-20T11:53:27.706727Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class EstimatorSelectionHelper:\n",
    "    \"\"\"\n",
    "    Set up grid search across multiple estimators, pipelines.\n",
    "    By David Bastista:\n",
    "    http://www.davidsbatista.net/blog/2018/02/23/model_optimization/\n",
    "    \"\"\"\n",
    "    #from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    cv=10\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" \n",
    "                             % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=cv, n_jobs=1, verbose=1, \n",
    "            scoring='accuracy', refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:53:28.730460Z",
     "start_time": "2019-07-20T11:53:28.726974Z"
    }
   },
   "outputs": [],
   "source": [
    "def bins(row):\n",
    "    \"\"\"\n",
    "    Assign weight fractions (continuous) to bins (int).\n",
    "    Class ranges are slightly different from those used by Isaacs et al. 2016.\n",
    "    \"\"\"\n",
    "    if row['maximum_weight_fraction'] <= 0.002:\n",
    "        val = 0 # low\n",
    "    elif row['maximum_weight_fraction'] > 0.05:\n",
    "        val = 2 # high\n",
    "    else:\n",
    "        val = 1 # medium\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:53:29.473244Z",
     "start_time": "2019-07-20T11:53:29.190432Z"
    }
   },
   "outputs": [],
   "source": [
    "bin_enm = np.asarray(y_enm.apply(bins, axis=1))\n",
    "bin_source = np.asarray(y_source.apply(bins, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:53:29.621233Z",
     "start_time": "2019-07-20T11:53:29.609189Z"
    }
   },
   "outputs": [],
   "source": [
    "def bar_graph_bins(label_data,\n",
    "                   data_composition):\n",
    "    \"\"\"\n",
    "    This function creates a bar graph of weight fraction bins and prints the \n",
    "    count and frequency for each.\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    label_data: int array of shape [n,]\n",
    "        Dataframe containing binned wf data\n",
    "    data_composition: string\n",
    "        Describes the chemical composition of label_data \n",
    "        for use in the plot title; e.g., `ENM`, `Organics`   \n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Find the count, frequency of WF bins\n",
    "    unique, counts = np.unique(label_data, return_counts=True)\n",
    "    wf_distrib = dict(zip(unique, counts))\n",
    "    freq = []\n",
    "    for i in counts:\n",
    "        percent = (i/np.sum(counts)).round(2)\n",
    "        freq.append(percent)\n",
    "\n",
    "    # Plot\n",
    "    plt.bar(range(len(wf_distrib)), list(wf_distrib.values()), align='center')\n",
    "    plt.xticks(range(len(wf_distrib)), list(['low','medium','high']))\n",
    "    plt.title('Frequency of %s Weight Fraction Bins' % data_composition)\n",
    "    plt.show()\n",
    "    \n",
    "    print('Label bin: ', unique)\n",
    "    print('Count    : ', counts)\n",
    "    print('Frequency: ', freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T20:07:28.740500Z",
     "start_time": "2019-07-22T20:07:28.650372Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_param_opt(param_grid, test_scores, scoring): \n",
    "    \n",
    "    \"\"\"\n",
    "    Optional plot of validation score vs classifier parameter(s). For use \n",
    "    after running parameter optimization with GridSearchCV.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    def convert_log_scale(n_set, n_label):\n",
    "        log_dif = np.abs(np.log10(max(n_set)) - np.log10(min(n_set)))\n",
    "        if log_dif > 3:\n",
    "            n_set = np.log10(n_set)\n",
    "            n_label = ('log_10(%s)' % n_label)    \n",
    "        return n_set, n_label\n",
    "\n",
    "    params = {k.split(\"__\")[1]: v for k, v in param_grid.items()}\n",
    "    param1 = list(params.keys())[0]\n",
    "    param1_set = list(params.values())[0]\n",
    "    param1_set, param1 = convert_log_scale(param1_set, param1)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    if len(param_grid.keys()) == 1:\n",
    "        plt.plot(param1_set, test_scores, 'k.-', ms=8, lw=2)\n",
    "        plt.title('%s vs %s' % (scoring.title(), param1))\n",
    "        plt.xlabel(param1)\n",
    "        plt.ylabel(scoring.title())\n",
    "        plt.xticks(np.arange(min(param1_set), max(param1_set) + 2, 2))\n",
    "    elif len(param_grid.keys()) == 2:\n",
    "        param2 = list(params.keys())[1]\n",
    "        param2_set = list(param_grid.values())[1]\n",
    "        param2_set, param2 = convert_log_scale(param2_set, param2)\n",
    "        test_scores = np.reshape(test_scores, newshape=[-1, len(param2_set)])\n",
    "        print(\"Score Dimensions: \", test_scores.shape)\n",
    "        plt.contourf(param2_set, param1_set, test_scores)\n",
    "        plt.title('%s Contours Over Parameter Grid' % scoring.title())\n",
    "        plt.xlabel(param2)\n",
    "        plt.ylabel(param1)\n",
    "        plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:53:30.577635Z",
     "start_time": "2019-07-20T11:53:30.566781Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_conf_matrix(cm, \n",
    "                     classes, \n",
    "                     normalize=False, \n",
    "                     title='Confusion Matrix', \n",
    "                     cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \n",
    "    Adapted from:\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import itertools\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "    plt.gcf().subplots_adjust(bottom=0.2)\n",
    "    plt.ylabel('True weight fraction')\n",
    "    plt.xlabel('Predicted weight fraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:53:31.762543Z",
     "start_time": "2019-07-20T11:53:31.742157Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_feat_impt(feature_names, \n",
    "                   importances, \n",
    "                   variances=None, \n",
    "                   save_fig_name=None,\n",
    "                   combo_impt=False):\n",
    "    \"\"\"\n",
    "    This function uses results from an rfc as input to plot feature importance.\n",
    "    Here, the rfc determines importance using what is known as gini importance \n",
    "    or mean decrease impurity. Includes option to combine features into more \n",
    "    easily interpretable groups.\n",
    "    \n",
    "    References:\n",
    "    https://stackoverflow.com/questions/15810339/how-are-feature-importances-in-randomforestclassifier-determined\n",
    "    https://matplotlib.org/examples/api/barchart_demo.html\n",
    "    https://stackoverflow.com/questions/28931224/adding-value-labels-on-a-matplotlib-bar-chart\n",
    "    \"\"\" \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # (Optional) Sum importance by feature group\n",
    "    if combo_impt:\n",
    "        feature_names = ['chemProperties', 'functions', 'productCategories', \n",
    "                               'productType', 'productMatrix']\n",
    "        importances = np.asarray([np.sum(importances[0:4]), \n",
    "                                  np.sum(importances[4:20]), \n",
    "                                  np.sum(importances[20:27]), \n",
    "                                  np.sum(importances[27:36]), \n",
    "                                  np.sum(importances[36:])])\n",
    "        # (Optional) Sum variance by feature group\n",
    "        if np.all(variances != None):\n",
    "            variances = np.asarray([np.sum(variances[0:4]), \n",
    "                                    np.sum(variances[4:20]),\n",
    "                                    np.sum(variances[20:27]),\n",
    "                                    np.sum(variances[27:36]),\n",
    "                                    np.sum(variances[36:])])\n",
    "    \n",
    "    indices = np.argsort(importances)\n",
    "    \n",
    "    # (Optional) Add error bars\n",
    "    if np.all(variances != None):\n",
    "        err_bars = np.sqrt(variances)\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.grid(True)\n",
    "        ax.barh(range(len(indices)), importances[indices], \n",
    "                 xerr=err_bars[indices], capsize=3, align='center')\n",
    "    else: \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.barh(range(len(indices)), importances[indices], align='center')\n",
    "    \n",
    "    # Add grid lines\n",
    "    plt.grid(False)\n",
    "    ax.set_xticks(np.arange(0, np.amax(importances)+0.1, 0.05))\n",
    "    ax.xaxis.grid(color='silver')\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    # Label parts of plot\n",
    "    ax.set_title('Feature Importance')\n",
    "    ax.set_xlabel('Relative Importance')\n",
    "    ax.set_yticks(np.arange(len(feature_names)))\n",
    "    ax.set_yticklabels([feature_names[i] for i in indices])\n",
    "    # Add importance value labels at the end of bars\n",
    "    if variances is None:\n",
    "        for rect in ax.patches:\n",
    "            # Get X and Y placement of label from rect\n",
    "            x_value = rect.get_width()\n",
    "            y_value = rect.get_y() + rect.get_height() / 2\n",
    "            # Use X value as label and format number with one decimal place\n",
    "            label = \"{:.2f}\".format(x_value)\n",
    "            # Create annotation\n",
    "            plt.annotate(\n",
    "                label,\n",
    "                (x_value, y_value),         # Place label at end of the bar\n",
    "                xytext=(4, 0),              # Horizontally shift label\n",
    "                textcoords=\"offset points\", # Interpret `xytext` as offset\n",
    "                va='center', ha='left')\n",
    "    \n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    if combo_impt: fig.set_size_inches(10, 6)\n",
    "    else: fig.set_size_inches(10, 10)\n",
    "    if np.all(save_fig_name != None):\n",
    "        fig.savefig('./figs/feature_importance_%s.png' % save_fig_name, \n",
    "                   bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:53:32.933719Z",
     "start_time": "2019-07-20T11:53:32.915877Z"
    }
   },
   "outputs": [],
   "source": [
    "def augment(aug_type, \n",
    "            k, \n",
    "            X_enm_train, \n",
    "            bin_enm_train, \n",
    "            random_state):\n",
    "    \n",
    "    \"\"\"\n",
    "    Augment ENM data with source (organics) data using either random \n",
    "    augmentation, unsupervised matching augmentation, or supervised matching \n",
    "    augmentation. Returns augmented data as numpy arrays.\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    aug_type: string ('none','random','uns_match', or 'sup_match')\n",
    "        The type of data augmentation to implement. \n",
    "        * none: no augmentation is performed; k must be zero.\n",
    "        * random: randomly samples source data to pair with ENM data.\n",
    "        * uns_match: match \"k\" most similar organics samples to ENM samples \n",
    "            based on smallest cosine distance between ENM and organics samples\n",
    "            (i.e., in an supervised fashion).\n",
    "        * sup_match: match \"k\" most similar organics samples to ENM samples \n",
    "            based on the smallest average of cosine distance between samples \n",
    "            and distance between WF labels (i.e., in an supervised fashion)\n",
    "    k: int ([0,200])\n",
    "        The number of organics samples to match with each ENM sample.\n",
    "    X_enm_train: DataFrame\n",
    "        ENM feature data to be augmented; typically a training subset for CV.\n",
    "    bin_enm_train: ndarray\n",
    "        ENM WF bin data to be augmented; typically a training subset for CV. \n",
    "    random_state: int\n",
    "        Which random seed to use.\n",
    "    \"\"\"\n",
    "    from numpy import random\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.metrics.pairwise import cosine_distances\n",
    "    \n",
    "    # ===No augmentation===\n",
    "    if (aug_type=='none' or k==0):\n",
    "        X_aug, bin_aug = X_enm_train, bin_enm_train\n",
    "    \n",
    "    else:\n",
    "        # ===Random augmentation===\n",
    "        if aug_type=='random': \n",
    "            n_samples = k * len(X_enm_train) # number of samples to select\n",
    "            # Obtain indices of randomly sampled source (organics) data\n",
    "            idx_match_name = X_source.sample(n=n_samples, \n",
    "                                             replace=False, \n",
    "                                             random_state=random_state, \n",
    "                                             axis=0).index\n",
    "            idx_match = [X_source.index.get_loc(i) for i in idx_match_name]\n",
    "            \n",
    "        # ===Matching augmentation===\n",
    "        else:\n",
    "            # Scale/normalize data\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            scaler.fit(np.concatenate((X_enm_train, X_source)))\n",
    "            X_enm_scaled = scaler.transform(X_enm_train)\n",
    "            X_source_scaled = scaler.transform(X_source)\n",
    "            \n",
    "            # Cosine distance matrix\n",
    "            cosdist_samples = cosine_distances(X_source_scaled, X_enm_scaled)\n",
    "\n",
    "            # For supervised matching augmentation, also consider WF labels\n",
    "            if aug_type=='sup_match':\n",
    "                # Turn 1D label arrays into 2D arrays\n",
    "                bin_enm_2d = np.tile(bin_enm_train, (len(bin_source), 1))\n",
    "                bin_source_2d = np.tile(bin_source, \n",
    "                                        (len(bin_enm_train), 1)).transpose()\n",
    "                # Get normalized distance between ENM and organics labels\n",
    "                dist_bins = scaler.fit_transform(\n",
    "                    np.abs(bin_enm_2d - bin_source_2d).astype(float))\n",
    "                # Average distances of features and labels\n",
    "                dist_matrix = (cosdist_samples + dist_bins) / 2\n",
    "            else:\n",
    "                # For unsupervised matching, use plain cosine distance matrix\n",
    "                dist_matrix = cosdist_samples\n",
    "\n",
    "            # For either unsupervised or supervised matching:\n",
    "            # Loop over distance matrix in search of k-smallest distances\n",
    "            idx_match = []\n",
    "            for col in dist_matrix.T:\n",
    "                # Find organics data indices of k-smallest distances\n",
    "                matches = np.argpartition(col, k)[:k]\n",
    "                idx_match.extend(matches)\n",
    "\n",
    "        # ===All augmentation===\n",
    "        # Create X and y data frames of matches using the matching index list\n",
    "        X_match = X_source.iloc[idx_match,:]\n",
    "        bin_match = bin_source[idx_match]\n",
    "\n",
    "        # Append sampled organics data to ENM data\n",
    "        X_aug = np.concatenate((X_enm_train, X_match))\n",
    "        bin_aug = np.concatenate((bin_enm_train, bin_match))\n",
    "\n",
    "    return X_aug, bin_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T21:28:37.861950Z",
     "start_time": "2019-07-22T21:28:37.829848Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define function to optimize, execute and evaluate a classifier using CV\n",
    "from numpy import random\n",
    "\n",
    "def model_opt_exe(classifier, \n",
    "                  aug_type, \n",
    "                  k, \n",
    "                  feat_data, \n",
    "                  bin_data, \n",
    "                  seed=random.randint(1,100),\n",
    "                  save_fig_name=None, \n",
    "                  show_opt_plot=False, \n",
    "                  show_feat_impt=False, \n",
    "                  show_cnf_matrix=False, \n",
    "                  param_grid=None):\n",
    "    \"\"\"\n",
    "    This function consists of three parts:\n",
    "    1) Optimize the parameters for a classifier, either SVC-RBF or RFC;     \n",
    "    2) Fit model pipeline to training data using optimized parameters and \n",
    "    stratified k-fold cross validation;\n",
    "    3) Execute the optimized model and summarize its accuracy in a confusion \n",
    "    matrix broken down by WF bins. Formatted confusion matrices are saved as \n",
    "    .png files.\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    classifier: string ('svc' or 'rfc')\n",
    "        The classifier to use in the pipeline; 'svc' refers to an SVC-RBF\n",
    "    aug_type: string ('none','random','uns_match', or 'sup_match')\n",
    "        The type of data augmentation to implement. \n",
    "        * none: no data augmentation is performed; k must be zero.\n",
    "        * random: randomly samples source data to pair with ENM data.\n",
    "        * uns_match: match \"k\" most similar organics samples to ENM samples \n",
    "            based on smallest cosine distance between ENM and organics samples\n",
    "            (i.e., in an supervised fashion).\n",
    "        * sup_match: match \"k\" most similar organics samples to ENM samples \n",
    "            based on the smallest average of cosine distance between samples \n",
    "            and distance between WF labels (i.e., in an supervised fashion)\n",
    "    k: int ([0,200])\n",
    "        The number of organics samples to match with each ENM sample.\n",
    "    feat_data: DataFrame\n",
    "        Feature data\n",
    "    bin_data: ndarray\n",
    "        WF bin data\n",
    "    seed: int (default=random.randint(1,100))\n",
    "        Option to set the seed for CV\n",
    "    save_fig_name: string (default=None)\n",
    "        A unique string used at the end of confusion matrix and feature \n",
    "        importance (rfc-only) file names for exporting the figures as .png; \n",
    "        `None` indicates that no figures should be saved\n",
    "    show_opt_plot: bool (default=False)\n",
    "        `True` will plot accuracy as contour lines on the specified parameter \n",
    "        grid (svc) or a line plot of accuracy vs n_trees (rfc)\n",
    "    show_cnf_matrix: bool (default=False)\n",
    "        `True` results in matrix graphics being printed as output\n",
    "    param_grid: dict (default=None)\n",
    "        See param_grid for sklearn's GridSearchCV\n",
    "    \"\"\"     \n",
    "    from numpy import random\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn import model_selection\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.metrics.pairwise import cosine_distances\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import accuracy_score ###############\n",
    "    from sklearn.metrics import balanced_accuracy_score ###############\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # =====PART 1=====\n",
    "    # Optimize parameters\n",
    "    \n",
    "    # Rename feature and label data\n",
    "    X = np.array(feat_data)\n",
    "    y = bin_data\n",
    "    # Rename parameter data\n",
    "    params = {k.split(\"__\")[1]: v for k, v in param_grid.items()}\n",
    "    param1_set, param2_set = [v for v in param_grid.values()]\n",
    "\n",
    "    # Cross validation settings\n",
    "    num_folds = 10\n",
    "    skfold = StratifiedKFold(n_splits=num_folds, \n",
    "                             shuffle=True, \n",
    "                             random_state=seed)\n",
    "    # Objects to hold performance results\n",
    "    train_accu = np.zeros([num_folds, len(param1_set),len(param2_set)])\n",
    "    valid_accu = np.zeros([num_folds, len(param1_set),len(param2_set)])\n",
    "    # Find best algorithm parameters by searching over a grid using the CV\n",
    "    # conditions specified above\n",
    "    q=0\n",
    "    for train_index, test_index in skfold.split(X, y):\n",
    "        # Split data\n",
    "        X_train, y_train = X[train_index], y[train_index]\n",
    "        X_valid, y_valid = X[test_index], y[test_index]\n",
    "        aug_group = np.concatenate((train_index, np.repeat(train_index, k)))\n",
    "        # Augment data (if applicable) using external function after data \n",
    "        # split to prevent data leakage\n",
    "        if not (aug_type=='none' or k==0): \n",
    "            X_train, y_train = blt.augment(aug_type, \n",
    "                                           k, \n",
    "                                           X_train, \n",
    "                                           y_train, \n",
    "                                           random_state=seed)\n",
    "        # Parameter grid search\n",
    "        r=0\n",
    "        for param1_val in param1_set:\n",
    "            s=0\n",
    "            for param2_val in param2_set:\n",
    "                fold_params = dict([(list(params.keys())[0], param1_val), \n",
    "                                    (list(params.keys())[1], param2_val)])\n",
    "                # Define pipeline options for parameter optimization\n",
    "                if classifier=='rfc':\n",
    "                    rfc = RandomForestClassifier(class_weight='balanced', \n",
    "                                                 random_state=seed, \n",
    "                                                 **fold_params)\n",
    "                    pipe = Pipeline([\n",
    "                        ('scale', MinMaxScaler()), # normalization from 0 to 1\n",
    "                        ('estimator', rfc)\n",
    "                    ])\n",
    "                else:\n",
    "                    svc = SVC(kernel='rbf', \n",
    "                              class_weight='balanced', # balance by WF bin size\n",
    "                              random_state=seed, \n",
    "                              **fold_params)\n",
    "                    pipe = Pipeline([\n",
    "                        ('scale', MinMaxScaler()), # normalization from 0 to 1\n",
    "                        ('estimator', svc)\n",
    "                    ])    \n",
    "                pipe.fit(X_train, y_train)\n",
    "                train_accu[q,r,s] = accuracy_score(y_train,     # y_true\n",
    "                                                   pipe.predict(X_train))\n",
    "                valid_accu[q,r,s] = accuracy_score(y_valid, \n",
    "                                                   pipe.predict(X_valid))\n",
    "                s+=1\n",
    "            r+=1\n",
    "        q+=1\n",
    "    \n",
    "    scoring = 'accuracy' # alternate option 'balanced_accuracy'\n",
    "    \n",
    "    # Average balanced accuracy for grid search settings\n",
    "    avg_train_accu = np.around(np.mean(train_accu, axis=0), decimals=3)\n",
    "    avg_valid_accu = np.around(np.mean(valid_accu, axis=0), decimals=3)\n",
    "\n",
    "    # Get coordinates of best accuracy to locate parameters\n",
    "    coords = np.argwhere(avg_valid_accu == np.max(avg_valid_accu))\n",
    "    best_params = dict([(list(params.keys())[0], param1_set[coords[0,0]]), \n",
    "                        (list(params.keys())[1], param2_set[coords[0,1]])])\n",
    "    # If optimization plotting is set as True, use plot_param_opt function\n",
    "    # to plot a 2D or contour plot to visualize accuracy \"hot spots\"\n",
    "    if show_opt_plot:\n",
    "        plot_param_opt(param_grid, avg_valid_accu, scoring)\n",
    "    \n",
    "    # Print best accuracy and parameter values\n",
    "    print('K-fold CV random state:\\t', seed)\n",
    "    print('Best fold %s:\\t%.4f' % (scoring, np.max(avg_valid_accu)))\n",
    "    print(\"Best Parameters: \", best_params)\n",
    "\n",
    "    # Play sound when done running\n",
    "    display(Audio(url=sound_file, autoplay=True))\n",
    "\n",
    "    return [v for v in best_params.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T06:38:27.675224Z",
     "start_time": "2019-07-18T06:38:27.647008Z"
    }
   },
   "source": [
    "# Define function to optimize, execute and evaluate a classifier using CV\n",
    "\n",
    "def model_opt_exe(classifier, \n",
    "                  aug_type, \n",
    "                  k, \n",
    "                  X_training, \n",
    "                  y_training, \n",
    "                  X_testing=X_enm, \n",
    "                  y_testing=bin_enm, \n",
    "                  seed=random.randint(1,100),\n",
    "                  save_fig_name=None, \n",
    "                  show_opt_plot=False, \n",
    "                  show_feat_impt=False, \n",
    "                  show_cnf_matrix=False, \n",
    "                  param_grid=None):\n",
    "    \"\"\"\n",
    "    This function consists of three parts:\n",
    "    1) Optimize the parameters for a classifier, either SVC-RBF or RFC;     \n",
    "    2) Fit model pipeline to training data using optimized parameters and \n",
    "    stratified k-fold cross validation;\n",
    "    3) Execute the optimized model and summarize its accuracy in a confusion \n",
    "    matrix broken down by WF bins. Formatted confusion matrices are saved as \n",
    "    .png files.\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    classifier: string ('svc' or 'rfc')\n",
    "        The classifier to use in the pipeline; 'svc' refers to an SVC-RBF\n",
    "    aug_type: string ('random','uns_match', or 'sup_match')\n",
    "        The type of data augmentation to implement. \n",
    "        * random: randomly samples source data to pair with ENM data.\n",
    "        * uns_match: match \"k\" most similar organics samples to ENM samples \n",
    "            based on smallest cosine distance between ENM and organics samples\n",
    "            (i.e., in an supervised fashion).\n",
    "        * sup_match: match \"k\" most similar organics samples to ENM samples \n",
    "            based on the smallest average of cosine distance between samples \n",
    "            and distance between WF labels (i.e., in an supervised fashion)\n",
    "    k: int ([0,200])\n",
    "        The number of organics samples to match with each ENM sample.\n",
    "    X_training: pandas data frame\n",
    "        Feature data frame to train the model on\n",
    "    y_training: pandas data frame\n",
    "        WF (labels) data frame to train the model on\n",
    "    X_testing: pandas data frame (default=X_enm)\n",
    "        Feature data frame to test the best model on\n",
    "    y_testing: pandas data frame (default=y_enm)\n",
    "        WF (labels) data frame to test the best model on   \n",
    "    seed: int (default=random.randint(1,100))\n",
    "        Option to set the seed for CV\n",
    "    save_fig_name: string (default=None)\n",
    "        A unique string used at the end of confusion matrix and feature \n",
    "        importance (rfc-only) file names for exporting the figures as .png; \n",
    "        `None` indicates that no figures should be saved\n",
    "    aug_group: array of int (default=None)\n",
    "        The array of ENM indices that augmented data were matched to; \n",
    "        applicable only to dfs with matching augmentation; prevents data leaks\n",
    "    show_opt_plot: bool (default=False)\n",
    "        `True` will plot accuracy as contour lines on the specified parameter \n",
    "        grid (svc) or a line plot of accuracy vs n_trees (rfc)\n",
    "    show_cnf_matrix: bool (default=False)\n",
    "        `True` results in matrix graphics being printed as output\n",
    "    param_grid: dict (default=None)\n",
    "        See param_grid for sklearn's GridSearchCV\n",
    "    \"\"\"     \n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn import model_selection\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import GroupKFold\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.metrics.pairwise import cosine_distances\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from numpy import random\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # =====PART 1=====\n",
    "    # Optimize parameters\n",
    "    \n",
    "    # Define pipeline options for parameter optimization\n",
    "    rfc = RandomForestClassifier(class_weight='balanced', \n",
    "                                 random_state=seed)\n",
    "    svc = SVC(kernel='rbf', \n",
    "              class_weight='balanced',  # balances weights of WF bins\n",
    "              random_state=seed)\n",
    "    if classifier=='rfc':               # set pipeline for RFC\n",
    "        pipe = Pipeline([\n",
    "            ('scale', MinMaxScaler()),  # normalization from 0 to 1\n",
    "            ('estimator', rfc)          # use RFC algorithm specified above\n",
    "        ])\n",
    "    else:                               # set pipeline for SVC-RBF\n",
    "        pipe = Pipeline([\n",
    "            ('scale', MinMaxScaler()),\n",
    "            ('estimator', svc)\n",
    "        ])\n",
    "\n",
    "    # Set what kind of stratified k-fold CV to run\n",
    "    num_folds = 10\n",
    "    # When matching augmentation was NOT used, run normal stratified k-fold CV\n",
    "    if np.all(aug_group == None):\n",
    "        cv = num_folds\n",
    "    # Run grouped stratified k-fold CV to keep each group of matched data \n",
    "    # samples together based on ENM index (aug_group) when splitting data into \n",
    "    # folds so that there is no data leakage\n",
    "    else: \n",
    "        gkf = GroupKFold(n_splits=num_folds)\n",
    "        gkf.random_state = seed\n",
    "        cv = gkf.split(X_training, y_training, aug_group)\n",
    "\n",
    "    # Find best algorithm parameters by searching over a grid using the CV\n",
    "    # and pipeline conditions specified above\n",
    "    \n",
    "#    # Augment training data using external function\n",
    "#    X_train, y_train, aug_group = blt.augment(aug_type, \n",
    "#                                             k, \n",
    "#                                             X_train, \n",
    "#                                             y_train, \n",
    "#                                             random_state=seed)\n",
    "    n_jobs = 3\n",
    "    scoring = 'accuracy'\n",
    "    grid_search = GridSearchCV(pipe, \n",
    "                               param_grid, \n",
    "                               cv=cv, \n",
    "                               scoring=scoring, \n",
    "                               n_jobs=n_jobs, \n",
    "                               pre_dispatch=2*n_jobs)\n",
    "    grid_search.fit(X_training, y_training)\n",
    "    \n",
    "    # Retrieve accuracy scores for all grid search settings\n",
    "    test_scores = grid_search.cv_results_.get('mean_test_score')\n",
    "    \n",
    "    # If optimization plotting is set as True, use plot_param_opt function\n",
    "    # to plot a 2D or contour plot to visualize accuracy \"hot spots\"\n",
    "    if show_opt_plot:\n",
    "        plot_param_opt(param_grid, test_scores, scoring)\n",
    "    \n",
    "    # Retrieve best parameters from grid search (using list comprehension)\n",
    "    best_params = {k.split(\"__\")[1]: v \n",
    "                   for k, v in grid_search.best_params_.items()}\n",
    "    \n",
    "    # Print best accuracy and parameter values\n",
    "    print('K-fold CV random state:\\t', seed)\n",
    "    print('Best fold %s:\\t%.4f' % (scoring, grid_search.best_score_))\n",
    "    for k, v in grid_search.best_params_.items(): \n",
    "        print('Best %s:\\t%.2e' % (k, v))\n",
    "    \n",
    "    # =====PART 2=====\n",
    "    # Fit optimized pipeline to training data\n",
    "    \n",
    "    # RFC pipeline                    \n",
    "    if classifier == 'rfc':\n",
    "        rfc = RandomForestClassifier(class_weight='balanced', \n",
    "                                     random_state=seed, \n",
    "                                     **best_params) # use optimized parameters\n",
    "        pipe = Pipeline([\n",
    "            ('scale', MinMaxScaler()),\n",
    "            ('estimator', rfc)\n",
    "        ])\n",
    "        pipe.fit(X_training, y_training)        # fit pipeline to training data\n",
    "        importances = rfc.feature_importances_  # get feature impt. from fit\n",
    "        \n",
    "        # Option to plot feature importance (RFC only)\n",
    "        if show_feat_impt:\n",
    "            feature_names = X_training.columns.values\n",
    "            plot_feat_impt(feature_names, importances, save_fig_name)      \n",
    "    \n",
    "    # SVC pipeline\n",
    "    else:\n",
    "        svc = SVC(kernel='rbf', \n",
    "                  class_weight='balanced', \n",
    "                  random_state=seed, \n",
    "                  **best_params)                # use optimized parameters\n",
    "        pipe = Pipeline([\n",
    "            ('scale', MinMaxScaler()),\n",
    "            ('estimator', svc)\n",
    "        ])\n",
    "        pipe.fit(X_training,y_training)\n",
    "    \n",
    "    # =====PART 3=====\n",
    "    # Model execution and performance summary\n",
    "    \n",
    "    X = np.array(X_testing)\n",
    "    y = np.array(y_testing)\n",
    "    \n",
    "    # Set CV as ~leave-one-out (based on sample size of the smallest WF bin)\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=17, # smallest bin size\n",
    "                                            shuffle=True, \n",
    "                                            random_state=seed)\n",
    "    \n",
    "    # Placeholder matrix of accuracies averaged across CV folds\n",
    "    cnf_matrix = np.zeros([3,3]) # 3 \"true\" vs 3 \"predicted\" WF bins\n",
    "    \n",
    "    # Run fitted pipeline using CV conditions defined above               \n",
    "    for train_index, test_index in kfold.split(X,y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        y_enm_predict = pipe.predict(X_test)\n",
    "        y[test_index] = y_enm_predict\n",
    "        # Write accuracy results to confusion matrix\n",
    "        cnf_matrix += confusion_matrix(y_test, y_enm_predict)\n",
    "    cnf_matrix = cnf_matrix.astype(np.int)\n",
    "    np.set_printoptions(precision=2)\n",
    "    class_names = [\"low\",\"mid\",\"high\"]\n",
    "\n",
    "    # Plot and save non-normalized confusion matrix\n",
    "    fig = plt.figure()\n",
    "    plot_conf_matrix(cnf_matrix, classes=class_names, normalize=False)\n",
    "    if np.all(save_fig_name != None):\n",
    "        fig.savefig('./figs/confusion_notnorm_%s.png' % save_fig_name)\n",
    "    if not show_cnf_matrix: plt.close(fig)\n",
    "\n",
    "    # Plot and save normalized confusion matrix\n",
    "    fig = plt.figure()\n",
    "    plot_conf_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                         title='Normalized Confusion Matrix')\n",
    "    if np.all(save_fig_name != None):\n",
    "        fig.savefig('./figs/confusion_norm_%s.png' % save_fig_name)\n",
    "    if not show_cnf_matrix: plt.close(fig)\n",
    "    \n",
    "    # Calculate the average normalized accuracy across all bins\n",
    "    cm_norm = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:,np.newaxis]\n",
    "    avg_norm = (cm_norm[0,0] + cm_norm[1,1] + cm_norm[2,2]) / 3\n",
    "    print('Average normalized accuracy: ', avg_norm)\n",
    "    \n",
    "    # Play sound when done running\n",
    "    display(Audio(url=sound_file, autoplay=True))\n",
    "    \n",
    "    # Set output based on chosen classifier\n",
    "    if classifier == 'rfc':\n",
    "        return avg_norm, importances\n",
    "    else:\n",
    "        return avg_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T11:53:46.203437Z",
     "start_time": "2019-07-20T11:53:46.190933Z"
    }
   },
   "outputs": [],
   "source": [
    "def multi_trials(num_trials, \n",
    "                 model_params):\n",
    "    \"\"\"\n",
    "    This function repeats model_opt_exe for a specified number of trials and\n",
    "    provides summary statistics. Returns avg mean (scalar), avg stdev \n",
    "    (scalar), and optionally, for RFC, arrays for average feature importance \n",
    "    and variance.\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    num_trials: int\n",
    "        The number of times to repeat\n",
    "    model_params: dict\n",
    "        A dictionary of parameters to run model_opt_exe \n",
    "    \"\"\"  \n",
    "    seed_set = np.random.choice(np.arange(1,101), \n",
    "                                size=num_trials, \n",
    "                                replace=False)\n",
    "    with HiddenPrints():   # Hides function output for all the trials\n",
    "        rs = []\n",
    "        for seed in seed_set:\n",
    "            model_params['seed'] = seed\n",
    "            # Apply all-in-one function that optimizes and executes model\n",
    "            rs_row = model_opt_exe(**model_params)\n",
    "            rs.append(rs_row)\n",
    "    # For RFC, write accuracy and feature importance results\n",
    "    if model_params['classifier'] == 'rfc':\n",
    "        results_accu = np.array([x for x, _ in rs]) # list comprehension\n",
    "        results_impt = np.array([y for _, y in rs])\n",
    "        avg_impt = results_impt.mean(axis=0)        # average importance\n",
    "        var_impt = results_impt.var(axis=0)         # variance of importance\n",
    "    # For SVC-RBF, only write accuracy results\n",
    "    else:\n",
    "        results_accu = np.array([x for x in rs])\n",
    "       \n",
    "    mu = results_accu.mean()   # average accuracy across trials\n",
    "    sigma = results_accu.std() # standard deviation\n",
    "    \n",
    "    # Print summary statistics across trials\n",
    "    print(\"Avg accuracy:    \", mu)\n",
    "    print(\"Median accuracy: \", np.median(results_accu))\n",
    "    print(\"StdDev accuracy: \", sigma)\n",
    "    print(\"Numer of trials: \", num_trials)\n",
    "    #print(\"Results: \", results_accu)\n",
    "    \n",
    "    # Play sound when done running\n",
    "    display(Audio(url=sound_file, autoplay=True))\n",
    "    \n",
    "    # Set output based on chosen classifier\n",
    "    if model_params['classifier'] == 'rfc':\n",
    "        return mu, sigma, avg_impt, var_impt\n",
    "    else: \n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T21:28:44.076416Z",
     "start_time": "2019-07-22T21:28:42.360808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook functions.ipynb to script\n",
      "[NbConvertApp] Writing 39786 bytes to functions.py\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    !jupyter nbconvert --to script functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
